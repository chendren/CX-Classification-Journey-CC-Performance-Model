# Fine-Tuning Dependencies

# Core libraries
torch>=2.1.0
transformers>=4.36.0
datasets>=2.14.0
accelerate>=0.24.0

# Parameter-efficient fine-tuning
peft>=0.7.0
bitsandbytes>=0.41.0

# Training utilities
wandb>=0.16.0  # Optional: for experiment tracking
tensorboard>=2.15.0

# Model evaluation
evaluate>=0.4.0
scikit-learn>=1.3.0

# Replicate (optional)
replicate>=0.20.0

# Configuration
pyyaml>=6.0
